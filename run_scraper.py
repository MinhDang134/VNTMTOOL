import asyncio
from datetime import datetime
import logging
import os
from src.tools.service import ScraperService
from src.tools.database import get_session, ensure_partition_exists # ensure_partition_exists c√≥ v·∫ª kh√¥ng c·∫ßn ·ªü ƒë√¢y n·ªØa

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
MEDIA_PHYSICAL_DIR = os.path.join(PROJECT_ROOT, "media_root", "brand_images")
os.makedirs(MEDIA_PHYSICAL_DIR, exist_ok=True)
logging.info(f"Th∆∞ m·ª•c l∆∞u tr·ªØ media: {MEDIA_PHYSICAL_DIR}")

async def run_scraper():
    scraper = ScraperService()
    start_date = datetime(2022, 2, 1)
    end_date = datetime(2022, 2, 3)

    with get_session() as session: # Context manager n√†y s·∫Ω t·ª± rollback n·∫øu c√≥ l·ªói kh√¥ng ƒë∆∞·ª£c x·ª≠ l√Ω
        try:
            logging.info(f"üöÄ B·∫Øt ƒë·∫ßu scrape t·ª´ {start_date.date()} ƒë·∫øn {end_date.date()}")
            brands = await scraper.scrape_by_date_range(start_date, end_date, session)
            if brands is not None: # brands l√† danh s√°ch tr·∫£ v·ªÅ t·ª´ service
                logging.info(f"‚úÖ Qu√° tr√¨nh scrape ho√†n t·∫•t. Service ƒë√£ x·ª≠ l√Ω {len(brands)} nh√£n hi·ªáu.")
            else:
                logging.warning("‚ÑπÔ∏è Qu√° tr√¨nh scrape c√≥ th·ªÉ ƒë√£ g·∫∑p l·ªói v√† kh√¥ng tr·∫£ v·ªÅ danh s√°ch nh√£n hi·ªáu.")
        except Exception as e:
            logging.error(f"‚ùå L·ªói nghi√™m tr·ªçng trong qu√° tr√¨nh ch·∫°y scraper: {str(e)}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(run_scraper())