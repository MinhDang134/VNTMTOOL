import asyncio
from datetime import datetime
import logging

from src.tools.service import ScraperService
from src.tools.database import get_session
from src.tools.database import ensure_partition_exists  # báº¡n nÃªn tÃ¡ch logic partition ra file riÃªng nhÆ° `partition.py`

# Cáº¥u hÃ¬nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

async def run_scraper():
    # âŒ KhÃ´ng cáº§n gá»i create_tables() náº¿u báº¡n Ä‘Ã£ táº¡o báº£ng partition thá»§ cÃ´ng
    # create_tables()  # Gá»i chá»— khÃ¡c náº¿u cáº§n cho cÃ¡c báº£ng khÃ¡c

    scraper = ScraperService()
    start_date = datetime(2022, 1, 1)
    end_date = datetime(2022, 3, 1)

    with get_session() as session:
        try:
            logging.info(f"ğŸš€ Báº¯t Ä‘áº§u scrape tá»« {start_date.date()} Ä‘áº¿n {end_date.date()}")

            # ğŸ‘‰ Gá»i scraper
            brands = await scraper.scrape_by_date_range(start_date, end_date, session)

            # ğŸ‘‰ Táº¡o partition (chá»‰ khi cáº§n)
            for brand in brands:
                ensure_partition_exists(brand.application_date)
                session.add(brand)

            session.commit()
            logging.info(f"âœ… ÄÃ£ scrape vÃ  lÆ°u {len(brands)} nhÃ£n hiá»‡u thÃ nh cÃ´ng.")

        except Exception as e:
            logging.error(f"âŒ Lá»—i khi cháº¡y scraper: {str(e)}")

if __name__ == "__main__":
    asyncio.run(run_scraper())
